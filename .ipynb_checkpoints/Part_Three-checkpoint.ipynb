{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00000f0-43b9-4f0b-ac6c-6cbcb99ff85f",
   "metadata": {},
   "source": [
    "# D - Next steps   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db299a-f8bd-400d-b482-b5b8afc63a3b",
   "metadata": {},
   "source": [
    "As the next steps, we will prepare the deployment pipeline for a Random Forest Regression model to transition seamlessly from development to production. \n",
    "\n",
    "Our deployment process will begin with building a draft API, incorporating endpoints for training, prediction, and log retrieval to ensure model retraining and usage monitoring. We'll containerize the API, model, and unit tests with Docker to enhance reproducibility and facilitate easy scaling across different environments. \n",
    "\n",
    "Applying test-driven development, we will iteratively refine the API to anticipate scale, load, and potential data drift over time, ensuring a robust model lifecycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7a155-1231-47c0-a93a-ac45897edaa9",
   "metadata": {},
   "source": [
    "## I - Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f605ddb-f4de-4b2d-8233-e53049a91adb",
   "metadata": {},
   "source": [
    "### 1 - Importing the necessary librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5f30f11-3303-46f8-bfc8-6a3e5dd439bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Necessary librairies imported\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import necessary libraries \n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import re\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "from data_module import load_json_data\n",
    "from cleaning_module import data_cleaning_pipeline\n",
    "from data_module import time_series_df\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('\\nNecessary librairies imported\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c10d9f-d268-48c3-a373-d9173ea03687",
   "metadata": {},
   "source": [
    "### 2 - Loading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0458e9d-0513-490c-a196-47291f1ec2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... Dataframe loaded as 'loaded_df'\n",
      "\n",
      "\n",
      "loaded_df contains initialy 815,011 rows\n",
      "\n",
      "\n",
      "Loading df runtime : 000:00:14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start timer for runtime\n",
    "loading_df_time_start = time.time()\n",
    "\n",
    "##Â loading the dataframe as loaded_df\n",
    "from data_module import load_json_data\n",
    "loaded_df_original = load_json_data('cs-train')\n",
    "print(f\"\\n... Dataframe loaded as 'loaded_df'\\n\")\n",
    "\n",
    "## Rows count\n",
    "print(f'\\nloaded_df contains initialy {len(loaded_df_original):,.0f} rows\\n')\n",
    "\n",
    "# calculate runtime duration\n",
    "m, s = divmod( time.time() - loading_df_time_start , 60)\n",
    "h, m = divmod(m, 60)\n",
    "loading_df_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "print(f'\\nLoading df runtime : {loading_df_runtime}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93245b75-08f1-4161-b83f-6e17ad7b17b8",
   "metadata": {},
   "source": [
    "### 3 - Cleaning the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a730955-5d84-4160-955e-d6dc867e2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data cleaning pipeline...\n",
      "\n",
      "\n",
      "Duplicate rows Summary\n",
      "----------------------\n",
      "\n",
      "The total number of rows before dropping duplicates is 815,011\n",
      "\n",
      "... Removed 28,844 duplicate rows.\n",
      "\n",
      "The total number of rows after dropping duplicates is 786,167\n",
      "\n",
      "\n",
      "The numerical columns are : times_viewed and price and year and month and day\n",
      "\n",
      "The total number of rows before dropping any invalid data is 786,167.\n",
      "\n",
      "\n",
      "Data Quality Summary\n",
      "--------------------------\n",
      "\n",
      "The total number of invalid data points in times_viewed is 7,714\n",
      "\n",
      "The total number of invalid data points in price is 5,252\n",
      "\n",
      "The total number of invalid data points in year is 0\n",
      "\n",
      "The total number of invalid data points in month is 0\n",
      "\n",
      "The total number of invalid data points in day is 0\n",
      "\n",
      "... Removed 12,328 rows with invalid data.\n",
      "\n",
      "The total number of rows after dropping all invalid data is 773,839.\n",
      "\n",
      "\n",
      "The numerical columns are : times_viewed and price and year and month and day\n",
      "\n",
      "\n",
      "There are 20,967 rows identified with outliers in times_viewed data\n",
      "\n",
      "There are 53,214 rows identified with outliers in price data\n",
      "\n",
      "There are 808 rows identified with outliers in year data\n",
      "\n",
      "There are 218 rows identified with outliers in month data\n",
      "\n",
      "There are 360 rows identified with outliers in day data\n",
      "\n",
      "Overall, there are 75,022 rows identified with outliers\n",
      "\n",
      "\n",
      "Outliers Summary\n",
      "--------------------------\n",
      "\n",
      "The total number of rows before dropping outliers is 773,839.\n",
      "\n",
      "... Removed 75,022 rows with outliers in the loaded_df_without_invalid_data.\n",
      "\n",
      "The total number of rows after dropping outliers is 698,817.\n",
      "\n",
      "\n",
      "\n",
      "Data cleaning pipeline completed.\n",
      "\n",
      "\n",
      "Cleaning runtime : 000:01:25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start timer for runtime\n",
    "cleaning_time_start = time.time()\n",
    "\n",
    "# clean the dataframe\n",
    "from cleaning_module import data_cleaning_pipeline\n",
    "loaded_df = data_cleaning_pipeline(loaded_df_original)\n",
    "\n",
    "# calculate runtime duration\n",
    "m, s = divmod( time.time() - cleaning_time_start , 60)\n",
    "h, m = divmod(m, 60)\n",
    "cleaning_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "print(f'\\nCleaning runtime : {cleaning_runtime}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a650a035-c8ee-4278-b967-9ce98fd889a9",
   "metadata": {},
   "source": [
    "### 4 - Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ddff8b9-7c9e-431d-99a4-80aea4397198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df, country, training):\n",
    "    \"\"\"\n",
    "    Engineer features for each day to predict the sum of revenue for the next 30 days.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing 'date' and 'revenue' columns.\n",
    "    training (bool): If True, trims the last 30 days of data; else, returns all data.\n",
    "\n",
    "    Returns:\n",
    "    X (pd.DataFrame): DataFrame with engineered features.\n",
    "    y (pd.Series): Target values (sum of next 30 days' revenue).\n",
    "    dates (pd.Series): Dates corresponding to each feature row.\n",
    "    \"\"\"\n",
    "\n",
    "    # start timer for runtime\n",
    "    engineer_features_time_start = time.time()\n",
    "\n",
    "    ts_df = time_series_df(df, country=country)\n",
    "    ts_df = ts_df[['date','revenue', 'purchases', 'total_views']]\n",
    "    # Ensure date dat type as datetime\n",
    "    ts_df['date'] = pd.to_datetime(ts_df['date'])\n",
    "\n",
    "    # Initialize dictionaries to store features and target values\n",
    "    eng_features = defaultdict(list)\n",
    "    y = []\n",
    "\n",
    "    # Define the look-back periods (in days) for feature engineering\n",
    "    previous_days = [7, 14, 28, 70]\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for idx , row in ts_df.iterrows():\n",
    "        current_date = row['date']\n",
    "\n",
    "        # Sum revenue for each specified look-back period\n",
    "        for num_days in previous_days:\n",
    "            start_date = current_date - pd.Timedelta(days=num_days)\n",
    "            revenue_sum = ts_df[(ts_df['date'] >= start_date) & (ts_df['date'] < current_date)]['revenue'].sum()\n",
    "            eng_features[f\"previous_{num_days}\"].append(revenue_sum)\n",
    "\n",
    "        # Target: Sum revenue for the next 30 days\n",
    "        target_sum = ts_df[(ts_df['date'] >= current_date) & (ts_df['date'] < current_date + pd.Timedelta(days=30))]['revenue'].sum()\n",
    "        y.append(target_sum)\n",
    "        \n",
    "        # Previous year revenue for trend analysis\n",
    "        prev_year_start = current_date - pd.DateOffset(years=1)\n",
    "        prev_year_end = prev_year_start + pd.DateOffset(days=30)\n",
    "        prev_year_revenue = ts_df[(ts_df['date'] >= prev_year_start) & (ts_df['date'] < prev_year_end)]['revenue'].sum()\n",
    "        eng_features['previous_year'].append(prev_year_revenue)\n",
    "        \n",
    "        # Non-revenue features: Average invoices and views over the last 30 days\n",
    "        recent_period_start = current_date - pd.Timedelta(days=30)\n",
    "        recent_data = ts_df[(ts_df['date'] >= recent_period_start) & (ts_df['date'] < current_date)]\n",
    "        eng_features['recent_views'].append(recent_data['total_views'].mean())\n",
    "    \n",
    "    # Convert the features dictionary to a DataFrame\n",
    "    X = pd.DataFrame(eng_features)\n",
    "    y = pd.Series(y, name='target')\n",
    "    dates = ts_df['date']\n",
    "\n",
    "    ## Remove rows with all zeros (in cases where no data exists for look-back periods)\n",
    "    X = X[(X != 0).any(axis=1)]\n",
    "    y = y[X.index]\n",
    "    dates = dates[X.index]\n",
    "\n",
    "    # If training, exclude the last 30 days to ensure target reliability\n",
    "    if training:\n",
    "        X = X.iloc[:-30]\n",
    "        y = y.iloc[:-30]\n",
    "        dates = dates.iloc[:-30]\n",
    "\n",
    "    # Reset index for neatness\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    dates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Calculate runtime duration\n",
    "    m, s = divmod( time.time() - engineer_features_time_start , 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    engineer_features_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "    print(f'\\nengineer_features runtime : {engineer_features_runtime}\\n')\n",
    "    return X, y, dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0910fc9-342b-4581-9ee3-a1362bbd2cc1",
   "metadata": {},
   "source": [
    "### 5 - Updating Log Training File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc374128-b50c-4e8b-9fac-c3bb0201bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_log(country, date_range, metric, runtime, version, prefix, note, mode= , test=False):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create Log Directory if it doesn't exist\n",
    "    if not os.path.isdir(LOG_DIR):\n",
    "        os.mkdir(LOG_DIR)\n",
    "    \n",
    "    # Name the logfile and and define its path\n",
    "    today = date.today()\n",
    "    train_logfile = os.path.join(LOG_DIR, f\"{prefix}-train-{today.month}-{today.year}.log\")\n",
    "    \n",
    "    # Define the header\n",
    "    header = ['unique_id', 'timestamp', 'date_range', 'country', 'metric', 'model_version', 'runtime', 'mode', 'note']\n",
    "    write_header = False\n",
    "    \n",
    "    # Write the header if needed\n",
    "    if not os.path.exists(train_logfile):\n",
    "        write_header = True\n",
    "        \n",
    "    # Get the current timestamp\n",
    "    current_timestamp = datetime.fromtimestamp(time.time()).strftime(\"%H:%M:%S\")\n",
    "\n",
    "    # Generate a random UUID\n",
    "    unique_id = uuid.uuid4()\n",
    "    unique_id = str(unique_id)[:13]\n",
    "    \n",
    "    # Write to CSV\n",
    "    with open(train_logfile, mode='a+', newline='') as csvfile: \n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        # Write the header if needed\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "        \n",
    "        # Prepare the row for writing\n",
    "        to_write = map(str, [unique_id, current_timestamp, date_range, country, metric, version, runtime, mode, note])\n",
    "        \n",
    "        # Write the row to the log file\n",
    "        writer.writerow(to_write)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa52cba-3880-4047-87c5-a64da3ad9a56",
   "metadata": {},
   "source": [
    "### 6 - Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75bda3f9-595f-43c2-b6bc-c00d96fa7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_training(df, country, prefix, version, model, model_param_grid, model_scaler, training, test) :       \n",
    "    \n",
    "    # start timer for runtime\n",
    "    perform_training_time_start = time.time()\n",
    "\n",
    "    # prepare the data\n",
    "    X, y, dates = engineer_features(df, country, training)\n",
    "\n",
    "    # Execute this block only if model is RandomForestRegressor\n",
    "    if isinstance(model, RandomForestRegressor):\n",
    "        X = X.dropna()  \n",
    "        y = y[X.index]\n",
    "        dates = dates[X.index]\n",
    "\n",
    "    # Create Test Subset of Data (if in Test Mode)\n",
    "    if test == True:\n",
    "        # Sample with replacement\n",
    "        subset = X.sample(frac=0.30, replace=False, random_state=42).index\n",
    "        dates = dates.loc[subset]\n",
    "        X = X.loc[subset]\n",
    "        y = y.loc[subset]\n",
    "\n",
    "    # Define the date range for logging\n",
    "    max_date = dates.iloc[-1].strftime('%Y-%m-%d')\n",
    "    min_date = dates.iloc[0].strftime('%Y-%m-%d')\n",
    "    date_range = f\"{min_date}:{max_date}\"\n",
    "    \n",
    "    # Perform a train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.20, shuffle=True)\n",
    "\n",
    "    # Create a pipeline with scaling and a random forest model\n",
    "    pipe = Pipeline([('model_scaler' , model_scaler) ,\n",
    "                     ('model'        , model ) ])\n",
    "    \n",
    "    print(\"\\n... Tuning the model hyperparameters \")\n",
    "    # Tune the hyperparameter\n",
    "    grid = GridSearchCV(pipe, param_grid=model_param_grid, cv=5, n_jobs=2)\n",
    "\n",
    "    # Fit the model on train set\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test set \n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    ## Evaluate the model on test set\n",
    "    # Calculate RMSE\n",
    "    eval_rmse = round(mean_squared_error(y_test, y_pred)**0.5)\n",
    "    print(f\"\\nEvaluated RMSE : {eval_rmse}\")\n",
    "    # Calculate MAPE\n",
    "    eval_mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "    print(f\"\\nEvaluated MAPE : {eval_mape:.2f}%\")\n",
    "    # Define the date range for logging\n",
    "    eval_metrics = f\"[RMSE={eval_rmse},MAPE={eval_mape:.1f}%]\"\n",
    "    \n",
    "    # retrain using all data\n",
    "    grid.fit(X, y)\n",
    "    print(\"\\n... Retraining model using all data\")\n",
    "\n",
    "    # Best model\n",
    "    fitted_model = grid.best_estimator_\n",
    "    print(\"\\nThe best fitted model :\", fitted_model, '\\n')\n",
    "\n",
    "    # make the model name more system compatible and file-friendly when saving the model\n",
    "    final_model_step = fitted_model.named_steps['model']  \n",
    "    model_name = final_model_step.__class__.__name__\n",
    "\n",
    "    # Define the file path when testing the model\n",
    "    if test:\n",
    "        saved_model = os.path.join(MODEL_DIR, f\"test-{country}-{model_name}-{version}.joblib\")\n",
    "        print(f\"\\n... saving test version of model: {saved_model}\\n\")\n",
    "        \n",
    "    # Define the path for any other usage with the model (e.g: evaluation, pre-production, production)\n",
    "    else:\n",
    "        saved_model = os.path.join(MODEL_DIR, f\"{prefix}-{country}-{model_name}-{version}.joblib\")\n",
    "        print(f\"\\n... saving model version for {prefix} : {saved_model}\\n\")\n",
    "\n",
    "    # Save the fitted model\n",
    "    joblib.dump(fitted_model , saved_model)\n",
    "    \n",
    "    # Calculate runtime duration\n",
    "    m, s = divmod(time.time()-perform_training_time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    perform_training_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "    print(f'perform_training runtime : {perform_training_runtime}\\n')\n",
    "\n",
    "    # update train log\n",
    "    update_train_log(country, date_range, eval_metrics, perform_training_runtime, version, prefix, test=False, note=NOTE)\n",
    "    \n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19898e7-cf05-45c4-b167-fe6313611cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(df, country, prefix, version, model, model_param_grid, model_scaler, training=True, test=False) :\n",
    "    \"\"\"\n",
    "    funtion to train model given a df\n",
    "    \n",
    "    'mode' -  can be used to subset data essentially simulating a train\n",
    "    \"\"\"\n",
    "    \n",
    "    # start timer for runtime\n",
    "    model_train_time_start = time.time()\n",
    "\n",
    "    # Create Model Directory if it doesn't exist\n",
    "    if not os.path.isdir(MODEL_DIR):\n",
    "        os.mkdir(MODEL_DIR)\n",
    "\n",
    "    if test:\n",
    "        print(\"...... testing\")\n",
    "        print(\"...... subseting data\")\n",
    "\n",
    "    # only train model for all countries and United Kingdom in test mode\n",
    "    #if country not in [ 'all_countries' , 'United Kingdom' ] and test :    \n",
    "    model_name = perform_training(df, country, prefix, version, model, model_param_grid, model_scaler, training, test)    \n",
    "    print(f'... model f\"{prefix}-{country}-{model_name}-{version} trained')\n",
    "\n",
    "    # Calculate runtime duration\n",
    "    m, s = divmod(time.time()-model_train_time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    model_train_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "    print(f'\\nmodel_train runtime : {model_train_runtime}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2d9f2-c17f-422e-afee-e8f43907d687",
   "metadata": {},
   "source": [
    "#### 5-1 - Execution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3bf0cd2-8677-45cd-beb6-f6b242730b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model specific variables (iterate the version and note with each change)\n",
    "NOTE      = \"random forest model for time-series\"\n",
    "MODEL_DIR = \"models\"\n",
    "version   = 'v3'\n",
    "mode      = 'dev'\n",
    "\n",
    "## Random Forest Regressor model specific variables \n",
    "model_prefix     = 'sl'\n",
    "country          = 'all_countries'\n",
    "model_scaler     = StandardScaler()\n",
    "model            = RandomForestRegressor( random_state = 42)\n",
    "model_param_grid = { 'model__n_estimators' : [90, 100, 110, 120, 130] ,\n",
    "                     'model__max_depth'    : [None, 5, 10, 15]        ,\n",
    "                     'model__criterion'    : ['squared_error']        }\n",
    "\n",
    "\n",
    "## log specific variables\n",
    "#LOG_DIR_PATH = os.path.join(os.path.dirname(__file__),'..','log')\n",
    "LOG_DIR = \"logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8be7b2d2-dcf6-4cd0-8774-9b5be52016c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "engineer_features runtime : 000:00:04\n",
      "\n",
      "\n",
      "... Tuning the model hyperparameters \n",
      "\n",
      "Evaluated RMSE : 8838\n",
      "\n",
      "Evaluated MAPE : 5.54%\n",
      "\n",
      "... Retraining model using all data\n",
      "\n",
      "The best fitted model : Pipeline(steps=[('model_scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestRegressor(max_depth=5, n_estimators=130,\n",
      "                                       random_state=42))]) \n",
      "\n",
      "\n",
      "... saving model version for sl : models/sl-all_countries-RandomForestRegressor-v4.joblib\n",
      "\n",
      "perform_training runtime : 000:00:46\n",
      "\n",
      "... model f\"sl-all_countries-RandomForestRegressor-v4 trained\n",
      "\n",
      "model_train runtime : 000:00:46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execution example\n",
    "\n",
    "model_train(loaded_df, country, prefix, version, model, model_param_grid, model_scaler, training=True, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edbd203-7bdb-42f4-aa1e-5c21fd677156",
   "metadata": {},
   "source": [
    "### 6 - Loading a Random Forest Regression Model Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd6c976f-05ed-45b7-b350-6da2b529996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(country, training, df=loaded_df, prefix='sl' ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # start timer for runtime\n",
    "    model_load_time_start = time.time()\n",
    "\n",
    "    # Initialize return values\n",
    "    all_data = None\n",
    "    all_models = None\n",
    "\n",
    "    # Retrieve all model filenames matching the specified prefix and country\n",
    "    models = [ filename for filename in os.listdir(\"./models\") if prefix in filename and country in filename ]\n",
    "\n",
    "    # Check if any models were found\n",
    "    if not models:\n",
    "        print(f\"Models starting with the prefix '{prefix}' for the '{country}' country cannot be found! Had you trained it?\")\n",
    "        return all_data, all_models  # Return None for both if no models are found\n",
    "\n",
    "    # Load models into a dictionary, keyed by country\n",
    "    all_models = { re.split(\".joblib\", model)[0] : joblib.load(os.path.join(\".\", \"models\", model)) for model in models }\n",
    "\n",
    "    # Engineer features and target variable from the provided DataFrame\n",
    "    X, y, dates = engineer_features(df, country, training)\n",
    "    # Convert dates to string format for consistency\n",
    "    dates = pd.to_datetime(dates).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Compile the data into a dictionary for easy access\n",
    "    all_data = { \"X\" : X , \"y\" : y , \"dates\" : dates }\n",
    "\n",
    "    # Calculate runtime duration\n",
    "    m, s = divmod(time.time()-model_load_time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    model_load_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "    print(f'\\nmodel_load runtime : {model_load_runtime}\\n')\n",
    "\n",
    "    return all_models , all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e8026-f0db-43fc-a0fd-8348ed5acb31",
   "metadata": {},
   "source": [
    "### 7 - Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e75715b-e535-47bd-8598-36dbf027aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_date(items, pivot):\n",
    "    return min(items, key=lambda x: abs(date.fromisoformat(x) - pivot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa0b25bf-2fbc-469c-ab1f-c47523932b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predict_log(country, target_date, y_pred, y_proba, runtime, version, mode):\n",
    "    \"\"\"\n",
    "    example function to update predict log file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Name the logfile and and define its path\n",
    "    today = date.today()\n",
    "    predict_logfile = os.path.join(LOG_DIR, f\"{mode}-predicted_on_{today.month}_{today.year}.log\")\n",
    "    \n",
    "    # Get the current timestamp\n",
    "    current_timestamp = datetime.fromtimestamp(time.time()).strftime(\"%H:%M:%S\")\n",
    "\n",
    "    # Generate a random UUID\n",
    "    unique_id = uuid.uuid4()\n",
    "    unique_id = str(unique_id)[:13]\n",
    "    \n",
    "    # Define the header\n",
    "    header = ['unique_id', 'timestamp', 'mode', 'country', 'target_date', 'y_pred', 'y_proba', 'model_version', 'runtime']\n",
    "    write_header = False\n",
    "    \n",
    "    # Write the header if needed\n",
    "    if not os.path.exists(predict_logfile):\n",
    "        write_header = True\n",
    "    \n",
    "    # Write to CSV\n",
    "    with open(predict_logfile, 'a+', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        # Write the header if needed\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "            \n",
    "        to_write = map(str, [unique_id, current_timestamp, mode, country, target_date, y_pred, y_proba, version, runtime])\n",
    "        writer.writerow(to_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9008c77f-ec94-4f43-b539-6b7fe1f4c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(df, country, year, month, day, mode='prod', all_models=None, training=False):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## start timer for runtime\n",
    "    model_predict_time_start = time.time()\n",
    "\n",
    "    ## load model if needed\n",
    "    if not all_models:\n",
    "        all_models , all_data = model_load(country, training, df, prefix='sl')\n",
    "\n",
    "    # input checks   \n",
    "    if not any(f'{country}' in key for key in all_models.keys()):\n",
    "        raise Exception(f\"\\nERROR (model_predict) - any model for country '{country}' could not be found\")\n",
    "\n",
    "    # Finding the model with the latest version\n",
    "    latest_model_key = max(all_models.keys(), key=lambda k: int(k.split('-')[-1][1:]))\n",
    "    latest_model = all_models[latest_model_key]\n",
    "    print(f\"\\nLatest Model used for {country} : {latest_model_key}\")    \n",
    "    \n",
    "    # Validate Date Components\n",
    "    for d in [year,month,day]:\n",
    "        if re.search(r\"\\D\", str(d)):  \n",
    "            raise Exception(\"ERROR (model_predict) - invalid year, month or day\")\n",
    "        \n",
    "    ## load data\n",
    "    data = all_data\n",
    "\n",
    "    # Convert dates to Datetime Format\n",
    "    dates = data['dates']\n",
    "    dates = pd.to_datetime(data['dates'])\n",
    "\n",
    "    # Check the target date\n",
    "    target_date = f\"{year}-{str(month).zfill(2)}-{str(day).zfill(2)}\"\n",
    "    print(f\"... Check if {target_date} is in the range.\")\n",
    "\n",
    "    # Validate Target Date and Find Nearest Date if Out of Range\n",
    "    if target_date not in dates.dt.strftime('%Y-%m-%d').values:\n",
    "        print(f\"ERROR (model_predict) - date {target_date} not in range [ {data['dates'].iloc[0]} - {data['dates'].iloc[-1]} ]\")\n",
    "        target_date = nearest(data['dates'], date.fromisoformat(target_date))\n",
    "        print(f\"Nearest target date is {target_date}\")\n",
    "    else:\n",
    "        print(\"Target date is in the range.\")\n",
    "\n",
    "    # Get the index of the target_date\n",
    "    target_date_indx = dates[dates == target_date].index[0]\n",
    "\n",
    "    # Query the corresponding row\n",
    "    query = data['X'].iloc[[target_date_indx]]  \n",
    "\n",
    "    ## sanity check\n",
    "    if data['dates'].shape[0] != data['X'].shape[0]:\n",
    "        raise Exception(\"ERROR (model_predict) - dimensions mismatch\")\n",
    "\n",
    "    ## make prediction\n",
    "    y_pred = latest_model.predict(query)\n",
    "\n",
    "    ## add a probability to the prediction \n",
    "    y_proba = None\n",
    "    if 'predict_proba' in dir(latest_model) and 'probability' in dir(latest_model):\n",
    "        if latest_model.probability == True:\n",
    "            y_proba = latest_model.predict_proba(query)\n",
    "\n",
    "    # Calculate runtime duration\n",
    "    m, s = divmod(time.time()-model_predict_time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    model_predict_runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "    print(f'\\nmodel_predict runtime : {model_predict_runtime}\\n')\n",
    "\n",
    "    # update predict log\n",
    "    update_predict_log(country, target_date, f'{y_pred[0]:,.0f}', y_proba, model_predict_runtime, version, mode)\n",
    "\n",
    "    return({'y_pred':f'{y_pred[0]:,.0f}' , 'y_proba':y_proba})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8878223-3baa-42ae-9269-399b1ef543d5",
   "metadata": {},
   "source": [
    "#### 7-1 - Execution example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "754b42eb-bbe9-4a33-91f6-ecbac95dd953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "engineer_features runtime : 000:00:11\n",
      "\n",
      "\n",
      "model_load runtime : 000:00:12\n",
      "\n",
      "\n",
      "Latest Model used for all_countries : sl-all_countries-RandomForestRegressor-v4\n",
      "... Check if 2019-07-30 is in the range.\n",
      "Target date is in the range.\n",
      "\n",
      "model_predict runtime : 000:00:12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y_pred': '83,442', 'y_proba': None}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict(loaded_df, 'all_countries', 2019, 7, 30, mode='prod', all_models=None, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63403301-54b0-43f9-b734-4ab5ed7afbbd",
   "metadata": {},
   "source": [
    "### 8 - Updating Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb334596-5bc6-42b3-a235-36e49ee4a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d5181-6be9-420e-8de1-d2c6be886798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
